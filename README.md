# ChatGPT Unit Test Generation

This project evaluates the quality of unit tests generated by OpenAi GPT-4 Turbo for various Java programs. It uses JaCoCo for code coverage analysis and JUnit for test execution.

## Project Structure

```
.
├── programs/           # Original Java programs
├── output_tests/       # Generated test files
├── lib/               # Dependencies (JUnit, JaCoCo)
├── evaluate_tests.py  # Main evaluation script
└── README.md         # This file
```

## Prerequisites

- Java Development Kit (JDK) 8 or higher
- Python 3.6 or higher
- Required Java libraries (included in `lib/` directory):
  - JUnit Jupiter API and Engine
  - JaCoCo Agent and CLI
  - JUnit Platform Console Standalone

## Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/ChatGPT_UnitTest_Generation.git
   cd ChatGPT_UnitTest_Generation
   ```

2. Ensure all required libraries are present in the `lib/` directory:
   - `junit-jupiter-api-5.8.0.jar`
   - `junit-jupiter-engine-5.8.0.jar`
   - `junit-platform-console-standalone-1.8.0.jar`
   - `jacoco-0.8.13/lib/jacocoagent.jar`
   - `jacoco-0.8.13/lib/jacococli.jar`

## Usage
Run the generation of Unit-Tests script:
```bash
python generate_and_fetch_tests.py
```

Run the evaluation script:
```bash
python evaluate_tests.py
```

The script will:
1. Compile all Java programs and their corresponding test files
2. Execute the tests with JaCoCo instrumentation
3. Generate coverage reports
4. Output results in both CSV and JSON formats

## Output

The evaluation results are saved in:
- `test_evaluation_results.csv`: Tabular format of test results
- `test_evaluation_results.json`: Detailed JSON format of test results

Each test file is evaluated for:
- Compilation success
- Test execution success
- Code coverage metrics:
  - Line coverage
  - Branch coverage
  - Method coverage